FROM openjdk:8

#ENV ENABLE_INIT_DAEMON true
#ENV INIT_DAEMON_BASE_URI http://identifier/init-daemon
#ENV INIT_DAEMON_STEP spark_master_init

ENV SPARK_VERSION=2.2.0
ENV HADOOP_VERSION=2.8.1

#COPY wait-for-step.sh /
#COPY execute-step.sh /
#COPY finish-step.sh /

#COPY bde-spark.css /css/org/apache/spark/ui/static/timeline-view.css

ADD https://raw.githubusercontent.com/guilhem/apt-get-install/master/apt-get-install /usr/bin/
RUN chmod +x /usr/bin/apt-get-install

RUN apt-get update && apt-get install -y curl && apt-get install wget \
      && chmod +x *.sh \
      && wget https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-without-hadoop.tgz \
      && tar -xvzf  spark-2.2.0-bin-without-hadoop.tgz \
      && mv spark-2.2.0-bin-without-hadoop spark \
      && rm  spark-2.2.0-bin-without-hadoop.tgz \
      #&& cd /css \
      #&& jar uf /spark/jars/spark-core_2.11-${SPARK_VERSION}.jar org/apache/spark/ui/static/timeline-view.css \
      && cd /

RUN apt-get-install -y python3 python3-setuptools python3-pip

RUN echo "export SPARK_DIST_CLASSPATH=$(hadoop classpath)" Â» /opt/spark-$SPARK_VERSION/conf/spark-env.sh
# Fix the value of PYTHONHASHSEED
# Note: this is needed when you use Python 3.3 or greater
ENV PYTHONHASHSEED 1
